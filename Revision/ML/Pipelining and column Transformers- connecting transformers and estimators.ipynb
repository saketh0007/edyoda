{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives \n",
    "* Problems with current code \n",
    "* Understanding Pipeline \n",
    "* Solving problems using Pipeline\n",
    "* challenges with PipeLine \n",
    "* Solving Hetroginous data problem with column transformers  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challanges of current data \n",
    "* Developers have to do manually the preprocessing followed by putting the data in Estimators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX,trainY,testY = train_test_split(digits.data,digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_tf = ss.fit_transform(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(trainX_tf,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX_tf = ss.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8, 6, 5, 0, 0, 8, 3, 9, 1, 4, 7, 6, 4, 3, 5, 8, 7, 4, 4, 4, 8,\n",
       "       3, 9, 6, 3, 6, 9, 0, 9, 6, 7, 3, 9, 3, 9, 5, 6, 6, 8, 3, 6, 4, 4,\n",
       "       7, 1, 2, 9, 9, 4, 9, 0, 9, 9, 6, 1, 4, 2, 0, 1, 2, 1, 2, 1, 1, 5,\n",
       "       0, 0, 9, 4, 7, 6, 9, 5, 7, 4, 7, 8, 7, 4, 3, 5, 6, 9, 8, 6, 9, 3,\n",
       "       5, 3, 5, 2, 8, 3, 8, 2, 6, 5, 2, 6, 8, 4, 5, 4, 1, 5, 7, 3, 6, 0,\n",
       "       5, 8, 6, 6, 6, 3, 4, 7, 5, 3, 7, 6, 9, 3, 8, 0, 2, 1, 6, 0, 9, 0,\n",
       "       6, 7, 6, 0, 4, 1, 3, 4, 3, 6, 2, 1, 8, 8, 2, 5, 3, 0, 5, 4, 7, 6,\n",
       "       0, 8, 4, 0, 5, 3, 6, 2, 5, 7, 1, 4, 3, 4, 3, 9, 9, 7, 3, 0, 4, 1,\n",
       "       2, 3, 3, 4, 8, 1, 9, 4, 4, 1, 9, 7, 3, 9, 7, 0, 0, 5, 6, 1, 1, 4,\n",
       "       3, 5, 6, 4, 6, 3, 8, 2, 3, 7, 4, 2, 2, 8, 1, 9, 3, 8, 7, 2, 8, 5,\n",
       "       9, 8, 4, 8, 2, 9, 0, 6, 3, 1, 6, 2, 1, 0, 8, 9, 0, 8, 9, 6, 1, 0,\n",
       "       1, 5, 6, 6, 7, 5, 8, 8, 9, 6, 1, 2, 4, 2, 2, 9, 3, 2, 7, 2, 9, 5,\n",
       "       0, 7, 4, 6, 5, 9, 6, 2, 5, 7, 7, 0, 9, 5, 1, 3, 0, 1, 5, 2, 5, 0,\n",
       "       9, 4, 7, 9, 6, 8, 9, 2, 4, 9, 8, 1, 8, 9, 4, 5, 8, 4, 5, 9, 6, 0,\n",
       "       3, 0, 0, 7, 7, 6, 8, 2, 2, 8, 5, 3, 3, 5, 2, 3, 2, 4, 5, 0, 9, 4,\n",
       "       2, 6, 4, 9, 2, 6, 8, 2, 2, 0, 4, 7, 6, 5, 8, 7, 4, 1, 9, 6, 4, 7,\n",
       "       4, 8, 1, 4, 3, 3, 1, 3, 3, 9, 2, 7, 0, 2, 4, 8, 8, 3, 5, 9, 7, 7,\n",
       "       1, 7, 9, 1, 4, 5, 6, 0, 0, 5, 1, 8, 2, 6, 6, 8, 3, 8, 2, 9, 3, 0,\n",
       "       6, 7, 0, 0, 4, 3, 6, 5, 0, 2, 5, 0, 4, 3, 5, 2, 0, 0, 5, 5, 9, 0,\n",
       "       3, 7, 4, 9, 6, 7, 9, 4, 9, 2, 9, 2, 2, 5, 4, 0, 2, 6, 9, 8, 1, 4,\n",
       "       6, 8, 2, 6, 7, 7, 0, 2, 5, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(testX_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New_way  \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chalanges of previous methods :\n",
    "* Different features need different preprocessing \n",
    "* It's very cumbersome to do things the current way \n",
    "* we have to preserve manually all the preprocessors used "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipe-Line \n",
    "* It connects preprocessors & estimators & thus removes the need to store them manually \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_pipeline = make_pipeline(StandardScaler(),RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8, 6, 5, 0, 0, 8, 3, 9, 1, 4, 7, 6, 4, 3, 5, 8, 7, 4, 4, 4, 8,\n",
       "       3, 9, 6, 3, 6, 9, 0, 9, 6, 7, 3, 9, 3, 9, 5, 6, 6, 8, 3, 6, 4, 4,\n",
       "       7, 1, 2, 9, 9, 4, 9, 0, 9, 9, 6, 1, 4, 2, 0, 1, 2, 1, 2, 1, 1, 5,\n",
       "       0, 0, 9, 4, 7, 6, 9, 5, 7, 4, 7, 8, 7, 4, 3, 5, 6, 9, 8, 6, 9, 3,\n",
       "       5, 3, 5, 2, 8, 3, 8, 2, 6, 5, 2, 6, 8, 4, 5, 4, 1, 5, 7, 3, 6, 0,\n",
       "       5, 8, 6, 6, 6, 8, 4, 7, 5, 3, 7, 6, 9, 3, 8, 0, 2, 1, 6, 0, 9, 0,\n",
       "       6, 7, 6, 0, 4, 1, 3, 4, 3, 6, 2, 1, 8, 8, 2, 5, 3, 0, 5, 4, 7, 6,\n",
       "       0, 8, 4, 0, 5, 3, 6, 2, 5, 7, 1, 4, 3, 4, 3, 9, 9, 7, 3, 0, 4, 1,\n",
       "       2, 3, 3, 4, 8, 1, 9, 4, 4, 1, 9, 7, 3, 9, 7, 0, 0, 5, 6, 1, 1, 4,\n",
       "       3, 5, 6, 4, 6, 3, 8, 2, 3, 7, 4, 2, 2, 8, 1, 9, 3, 8, 7, 8, 8, 5,\n",
       "       5, 8, 4, 8, 2, 5, 0, 6, 3, 1, 6, 2, 1, 0, 7, 9, 0, 8, 9, 6, 1, 0,\n",
       "       1, 5, 6, 6, 7, 5, 8, 8, 9, 6, 1, 2, 4, 2, 2, 9, 3, 2, 7, 2, 9, 4,\n",
       "       0, 7, 4, 6, 5, 9, 6, 2, 5, 7, 7, 0, 9, 5, 1, 3, 0, 1, 5, 2, 5, 0,\n",
       "       9, 8, 7, 9, 6, 8, 9, 2, 4, 9, 8, 1, 8, 9, 4, 5, 8, 4, 5, 9, 6, 0,\n",
       "       3, 0, 0, 7, 7, 6, 8, 2, 2, 8, 5, 3, 3, 5, 2, 3, 2, 4, 5, 0, 9, 4,\n",
       "       2, 6, 4, 9, 2, 6, 8, 2, 2, 0, 4, 7, 6, 5, 8, 7, 4, 1, 9, 6, 4, 7,\n",
       "       4, 8, 1, 4, 3, 3, 1, 3, 3, 9, 2, 7, 0, 2, 4, 8, 8, 3, 3, 9, 7, 7,\n",
       "       1, 7, 9, 1, 4, 5, 6, 0, 0, 5, 1, 8, 2, 6, 6, 8, 3, 8, 2, 9, 3, 0,\n",
       "       6, 7, 0, 0, 4, 3, 6, 5, 0, 2, 5, 0, 4, 3, 5, 2, 0, 0, 5, 5, 9, 0,\n",
       "       3, 7, 4, 9, 6, 7, 9, 4, 9, 2, 9, 2, 2, 5, 4, 0, 2, 6, 9, 8, 1, 4,\n",
       "       6, 8, 2, 6, 7, 7, 0, 2, 5, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standardscaler', StandardScaler()),\n",
       " ('randomforestclassifier', RandomForestClassifier())]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 2.41666859e-03, 1.96529987e-02, 1.01025654e-02,\n",
       "       1.11930086e-02, 2.16128105e-02, 8.47716050e-03, 6.07525502e-04,\n",
       "       9.19416758e-05, 1.12071422e-02, 2.79756324e-02, 6.51171476e-03,\n",
       "       1.83181569e-02, 2.80403563e-02, 5.51219707e-03, 9.67818832e-04,\n",
       "       1.16581909e-04, 7.95422267e-03, 2.05226270e-02, 2.69000311e-02,\n",
       "       3.00697866e-02, 5.14033981e-02, 9.43868442e-03, 1.63831738e-04,\n",
       "       3.70268291e-05, 1.32975949e-02, 3.98377515e-02, 2.56342643e-02,\n",
       "       2.94145225e-02, 2.63251295e-02, 2.88009607e-02, 1.05198294e-04,\n",
       "       0.00000000e+00, 3.27005835e-02, 2.43292305e-02, 1.98075556e-02,\n",
       "       3.77541404e-02, 1.95209982e-02, 2.42027270e-02, 0.00000000e+00,\n",
       "       3.12391853e-05, 8.81951870e-03, 3.58209084e-02, 4.29824858e-02,\n",
       "       2.20820907e-02, 1.66242259e-02, 2.11326754e-02, 6.70426107e-05,\n",
       "       2.20191101e-05, 2.81700544e-03, 1.94265236e-02, 2.09559976e-02,\n",
       "       1.40494760e-02, 2.11000679e-02, 1.98629634e-02, 2.12907344e-03,\n",
       "       1.56770862e-05, 2.20534822e-03, 2.07223830e-02, 1.17706932e-02,\n",
       "       2.90799276e-02, 2.81703669e-02, 1.62430510e-02, 2.84469466e-03])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## connecting pipeline with Hyper Parameter tuning \n",
    "* we could determine the best cobination of hyper-parameters for preprocessor and estimators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_pipeline = make_pipeline(StandardScaler(),SelectKBest(k=10,score_func = f_classif),RandomForestClassifier(n_estimators= 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('selectkbest', SelectKBest()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standardscaler', StandardScaler()),\n",
       " ('selectkbest', SelectKBest()),\n",
       " ('randomforestclassifier', RandomForestClassifier())]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = {'selectbest__k':[20,30,40],'randomforestclassifier__n_estimators':[100,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'selectkbest__k':[50,55,60], 'randomforestclassifier__n_estimators':[200,250]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(digit_pipeline, param_grid=params, cv=5, n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saket\\Anaconda333\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: UserWarning: Features [ 0 32 39] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\saket\\Anaconda333\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('selectkbest', SelectKBest()),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'randomforestclassifier__n_estimators': [200, 250],\n",
       "                         'selectkbest__k': [50, 55, 60]})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestclassifier__n_estimators': 200, 'selectkbest__k': 55}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740217540961034"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 7])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.predict(testX[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('selectkbest', SelectKBest(k=55)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(n_estimators=200))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column transformers for dealing with hetrogenous data \n",
    "* Regular preprocessing tends to do same preprocessing for all the columns \n",
    "* This does't work for hetrogenious data \n",
    "     - heterogeneous\n",
    "        - diverse in character or content.\n",
    "            - \"a large and heterogeneous collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://camo.githubusercontent.com/82ec7d9816d964e54f028d2ce5223ac529dd740e/68747470733a2f2f6769746875622e636f6d2f6564796f64612f446174612d536369656e746973742d70726f6772616d2f626c6f622f6d61737465722f41737369676e6d656e742f696d616765732f436f6c756d6e5472616e666f726d65722e706e673f7261773d74727565\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data = pd.read_csv('https://raw.githubusercontent.com/edyoda/data-science-complete-tutorial/master/Data/HR_comma_sep.csv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data.rename(columns={'sales':'dept'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4776</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3</td>\n",
       "      <td>243</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4</td>\n",
       "      <td>195</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9629</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.53</td>\n",
       "      <td>5</td>\n",
       "      <td>160</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3</td>\n",
       "      <td>194</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12821</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.58</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accounting</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12909</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.65</td>\n",
       "      <td>5</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2</td>\n",
       "      <td>154</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "4776                 0.63             0.64               3   \n",
       "2176                 0.82             0.73               4   \n",
       "9629                 0.22             0.53               5   \n",
       "8766                 0.21             0.84               3   \n",
       "92                   0.42             0.48               2   \n",
       "2220                 0.75             0.51               4   \n",
       "12821                0.19             0.58               4   \n",
       "12909                0.88             0.65               5   \n",
       "10692                0.71             0.90               3   \n",
       "1641                 0.41             0.56               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "4776                    243                   3              0     0   \n",
       "2176                    195                   5              1     0   \n",
       "9629                    160                   4              1     0   \n",
       "8766                    194                   2              0     0   \n",
       "92                      143                   3              0     1   \n",
       "2220                    138                   4              0     0   \n",
       "12821                   173                   5              0     0   \n",
       "12909                   228                   3              0     0   \n",
       "10692                   138                   3              0     0   \n",
       "1641                    154                   3              0     1   \n",
       "\n",
       "       promotion_last_5years        dept  salary  \n",
       "4776                       0   technical  medium  \n",
       "2176                       0   technical  medium  \n",
       "9629                       0       sales  medium  \n",
       "8766                       0          IT  medium  \n",
       "92                         0       sales     low  \n",
       "2220                       0   marketing  medium  \n",
       "12821                      0  accounting  medium  \n",
       "12909                      0       sales  medium  \n",
       "10692                      0   marketing  medium  \n",
       "1641                       0   technical     low  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data= hr_data.drop(columns = ['left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = hr_data.left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Different columns need different columns need different preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = feature_data.select_dtypes(include= ['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction_level       float64\n",
       "last_evaluation          float64\n",
       "number_project             int64\n",
       "average_montly_hours       int64\n",
       "time_spend_company         int64\n",
       "Work_accident              int64\n",
       "promotion_last_5years      int64\n",
       "dept                      object\n",
       "salary                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#satisfaction_level & last_evaluation don't need preprocessing\n",
    "#number_project,average_montly_hours,time_spend_company,Work_accident,promotion_last_5years need MinMaxScaler\n",
    "#dept & Salary need OrdinalEncoder\n",
    "feature_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = feature_data.select_dtypes(include = ['int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_data = feature_data.select_dtypes(include = ['float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation\n",
       "0                0.38             0.53\n",
       "1                0.80             0.86\n",
       "2                0.11             0.88\n",
       "3                0.72             0.87"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_pipeline = make_pipeline(SimpleImputer(),OrdinalEncoder())\n",
    "#SimpleImpter is for handling missing data in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = make_pipeline(OrdinalEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_pipeline = make_pipeline(MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "               (cat_pipeline,cat_data.columns),\n",
    "                (int_pipeline,num_data.columns),\n",
    "                 remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessor,RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX, trainY, testY = train_test_split(feature_data, target_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accounting</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9825</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      satisfaction_level  last_evaluation  number_project  \\\n",
       "4962                0.89             0.55               4   \n",
       "9825                0.87             0.70               3   \n",
       "\n",
       "      average_montly_hours  time_spend_company  Work_accident  \\\n",
       "4962                   196                   2              0   \n",
       "9825                   224                   3              0   \n",
       "\n",
       "      promotion_last_5years        dept  salary  \n",
       "4962                      0  accounting  medium  \n",
       "9825                      0     support     low  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('ordinalencoder',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  Index(['dept', 'salary'], dtype='object')),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('minmaxscaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index([], dtype='object'))])),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(testX[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pipeline-1',\n",
       "  Pipeline(steps=[('ordinalencoder', OrdinalEncoder())]),\n",
       "  Index(['dept', 'salary'], dtype='object')),\n",
       " ('pipeline-2',\n",
       "  Pipeline(steps=[('minmaxscaler', MinMaxScaler())]),\n",
       "  Index([], dtype='object'))]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps[0][1].transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'columntransformer__pipeline-2__selectkbest__k':[2,3]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MinMaxScaler in module sklearn.preprocessing._data:\n",
      "\n",
      "class MinMaxScaler(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  MinMaxScaler(feature_range=(0, 1), *, copy=True)\n",
      " |  \n",
      " |  Transform features by scaling each feature to a given range.\n",
      " |  \n",
      " |  This estimator scales and translates each feature individually such\n",
      " |  that it is in the given range on the training set, e.g. between\n",
      " |  zero and one.\n",
      " |  \n",
      " |  The transformation is given by::\n",
      " |  \n",
      " |      X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
      " |      X_scaled = X_std * (max - min) + min\n",
      " |  \n",
      " |  where min, max = feature_range.\n",
      " |  \n",
      " |  This transformation is often used as an alternative to zero mean,\n",
      " |  unit variance scaling.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  feature_range : tuple (min, max), default=(0, 1)\n",
      " |      Desired range of transformed data.\n",
      " |  \n",
      " |  copy : bool, default=True\n",
      " |      Set to False to perform inplace row normalization and avoid a\n",
      " |      copy (if the input is already a numpy array).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  min_ : ndarray of shape (n_features,)\n",
      " |      Per feature adjustment for minimum. Equivalent to\n",
      " |      ``min - X.min(axis=0) * self.scale_``\n",
      " |  \n",
      " |  scale_ : ndarray of shape (n_features,)\n",
      " |      Per feature relative scaling of the data. Equivalent to\n",
      " |      ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_* attribute.\n",
      " |  \n",
      " |  data_min_ : ndarray of shape (n_features,)\n",
      " |      Per feature minimum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_min_*\n",
      " |  \n",
      " |  data_max_ : ndarray of shape (n_features,)\n",
      " |      Per feature maximum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_max_*\n",
      " |  \n",
      " |  data_range_ : ndarray of shape (n_features,)\n",
      " |      Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_range_*\n",
      " |  \n",
      " |  n_samples_seen_ : int\n",
      " |      The number of samples processed by the estimator.\n",
      " |      It will be reset on new calls to fit, but increments across\n",
      " |      ``partial_fit`` calls.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import MinMaxScaler\n",
      " |  >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      " |  >>> scaler = MinMaxScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  MinMaxScaler()\n",
      " |  >>> print(scaler.data_max_)\n",
      " |  [ 1. 18.]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[0.   0.  ]\n",
      " |   [0.25 0.25]\n",
      " |   [0.5  0.5 ]\n",
      " |   [1.   1.  ]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[1.5 0. ]]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  minmax_scale: Equivalent function without the estimator API.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |  \n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MinMaxScaler\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, feature_range=(0, 1), *, copy=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute the minimum and maximum to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data used to compute the per-feature minimum and maximum\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Undo the scaling of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data that will be transformed. It cannot be sparse.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : array-like of shape (n_samples, n_features)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None)\n",
      " |      Online computation of min and max on X for later scaling.\n",
      " |      \n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when :meth:`fit` is not feasible due to very large number of\n",
      " |      `n_samples` or because X is read from a continuous stream.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Transformer instance.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Scale features of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data that will be transformed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : array-like of shape (n_samples, n_features)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features)\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,), default=None\n",
      " |          Target values.\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipeline, param_grid=params, n_jobs=4, cv=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gs.best_params_\n",
    "gs.best_params_\n",
    "gs.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages of pipeline \n",
    "* Does'nt support online learning \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the imbalanced classes in pipeline \n",
    "* using imblearn make_pipeline rather than scikit make pipeline as Randomoversampler is not suitede for scikit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11428\n",
       "1     3571\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This make_pipeline is not scikit pipeline but imblearn pipeline which support Oversampler as part of pipeline\n",
    "pipeline = make_pipeline(preprocessor, RandomOverSampler(), RandomForestClassifier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('ordinalencoder',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  Index(['dept', 'salary'], dtype='object')),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('minmaxscaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index([], dtype='object'))])),\n",
       "                ('randomoversampler', RandomOverSampler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
