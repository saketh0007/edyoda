{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data = pd.read_csv('https://raw.githubusercontent.com/edyoda/data-science-complete-tutorial/master/Data/churn.csv.txt', parse_dates=['last_trip_date','signup_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is there any churn in the data\n",
    "* Many times target is not directly given \n",
    "* It has to be derived from the feature columns \n",
    "* From the data,we need to identify the data on which the data was downloaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   avg_dist  avg_rating_by_driver  avg_rating_of_driver  avg_surge  \\\n0      3.67                   5.0                   4.7       1.10   \n1      8.26                   5.0                   5.0       1.00   \n2      0.77                   5.0                   4.3       1.00   \n3      2.36                   4.9                   4.6       1.14   \n4      3.13                   4.9                   4.4       1.19   \n\n             city last_trip_date    phone signup_date  surge_pct  \\\n0  King's Landing     2014-06-17   iPhone  2014-01-25       15.4   \n1         Astapor     2014-05-05  Android  2014-01-29        0.0   \n2         Astapor     2014-01-07   iPhone  2014-01-06        0.0   \n3  King's Landing     2014-06-29   iPhone  2014-01-10       20.0   \n4      Winterfell     2014-03-15  Android  2014-01-27       11.8   \n\n   trips_in_first_30_days  luxury_car_user  weekday_pct  \n0                       4             True         46.2  \n1                       0            False         50.0  \n2                       3            False        100.0  \n3                       9             True         80.0  \n4                      14            False         82.4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avg_dist</th>\n      <th>avg_rating_by_driver</th>\n      <th>avg_rating_of_driver</th>\n      <th>avg_surge</th>\n      <th>city</th>\n      <th>last_trip_date</th>\n      <th>phone</th>\n      <th>signup_date</th>\n      <th>surge_pct</th>\n      <th>trips_in_first_30_days</th>\n      <th>luxury_car_user</th>\n      <th>weekday_pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.67</td>\n      <td>5.0</td>\n      <td>4.7</td>\n      <td>1.10</td>\n      <td>King's Landing</td>\n      <td>2014-06-17</td>\n      <td>iPhone</td>\n      <td>2014-01-25</td>\n      <td>15.4</td>\n      <td>4</td>\n      <td>True</td>\n      <td>46.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.26</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>1.00</td>\n      <td>Astapor</td>\n      <td>2014-05-05</td>\n      <td>Android</td>\n      <td>2014-01-29</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.77</td>\n      <td>5.0</td>\n      <td>4.3</td>\n      <td>1.00</td>\n      <td>Astapor</td>\n      <td>2014-01-07</td>\n      <td>iPhone</td>\n      <td>2014-01-06</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>False</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.36</td>\n      <td>4.9</td>\n      <td>4.6</td>\n      <td>1.14</td>\n      <td>King's Landing</td>\n      <td>2014-06-29</td>\n      <td>iPhone</td>\n      <td>2014-01-10</td>\n      <td>20.0</td>\n      <td>9</td>\n      <td>True</td>\n      <td>80.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.13</td>\n      <td>4.9</td>\n      <td>4.4</td>\n      <td>1.19</td>\n      <td>Winterfell</td>\n      <td>2014-03-15</td>\n      <td>Android</td>\n      <td>2014-01-27</td>\n      <td>11.8</td>\n      <td>14</td>\n      <td>False</td>\n      <td>82.4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Timestamp('2014-07-01 00:00:00')"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "churn_data.last_trip_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = churn_data.last_trip_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = last_date-datetime.timedelta(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If an user did't come after date he/she is considered as churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data['churn'] = churn_data.last_trip_date.map(lambda d: 'Not churn' if d > cutoff_date else 'churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       avg_dist  avg_rating_by_driver  avg_rating_of_driver  avg_surge  \\\n34198      5.22                   4.9                   4.8       1.04   \n\n             city last_trip_date   phone signup_date  surge_pct  \\\n34198  Winterfell     2014-06-11  iPhone  2014-01-16        3.8   \n\n       trips_in_first_30_days  luxury_car_user  weekday_pct      churn  \n34198                       1             True         84.6  Not churn  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avg_dist</th>\n      <th>avg_rating_by_driver</th>\n      <th>avg_rating_of_driver</th>\n      <th>avg_surge</th>\n      <th>city</th>\n      <th>last_trip_date</th>\n      <th>phone</th>\n      <th>signup_date</th>\n      <th>surge_pct</th>\n      <th>trips_in_first_30_days</th>\n      <th>luxury_car_user</th>\n      <th>weekday_pct</th>\n      <th>churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>34198</th>\n      <td>5.22</td>\n      <td>4.9</td>\n      <td>4.8</td>\n      <td>1.04</td>\n      <td>Winterfell</td>\n      <td>2014-06-11</td>\n      <td>iPhone</td>\n      <td>2014-01-16</td>\n      <td>3.8</td>\n      <td>1</td>\n      <td>True</td>\n      <td>84.6</td>\n      <td>Not churn</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "churn_data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "avg_dist                         float64\navg_rating_by_driver             float64\navg_rating_of_driver             float64\navg_surge                        float64\ncity                              object\nlast_trip_date            datetime64[ns]\nphone                             object\nsignup_date               datetime64[ns]\nsurge_pct                        float64\ntrips_in_first_30_days             int64\nluxury_car_user                     bool\nweekday_pct                      float64\nchurn                             object\ndtype: object"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "churn_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50000 entries, 0 to 49999\nData columns (total 13 columns):\n #   Column                  Non-Null Count  Dtype         \n---  ------                  --------------  -----         \n 0   avg_dist                50000 non-null  float64       \n 1   avg_rating_by_driver    49799 non-null  float64       \n 2   avg_rating_of_driver    41878 non-null  float64       \n 3   avg_surge               50000 non-null  float64       \n 4   city                    50000 non-null  object        \n 5   last_trip_date          50000 non-null  datetime64[ns]\n 6   phone                   49604 non-null  object        \n 7   signup_date             50000 non-null  datetime64[ns]\n 8   surge_pct               50000 non-null  float64       \n 9   trips_in_first_30_days  50000 non-null  int64         \n 10  luxury_car_user         50000 non-null  bool          \n 11  weekday_pct             50000 non-null  float64       \n 12  churn                   50000 non-null  object        \ndtypes: bool(1), datetime64[ns](2), float64(6), int64(1), object(3)\nmemory usage: 4.1+ MB\n"
    }
   ],
   "source": [
    "churn_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_churn_data = churn_data.select_dtypes(include = ['float','bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50000 entries, 0 to 49999\nData columns (total 7 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   avg_dist              50000 non-null  float64\n 1   avg_rating_by_driver  49799 non-null  float64\n 2   avg_rating_of_driver  41878 non-null  float64\n 3   avg_surge             50000 non-null  float64\n 4   surge_pct             50000 non-null  float64\n 5   luxury_car_user       50000 non-null  bool   \n 6   weekday_pct           50000 non-null  float64\ndtypes: bool(1), float64(6)\nmemory usage: 2.3 MB\n"
    }
   ],
   "source": [
    "float_churn_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_churn_data = churn_data[['city','phone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_pipeline = make_pipeline(SimpleImputer(strategy='median'),MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'),OrdinalEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data['subscription_days'] = churn_data.last_trip_date - churn_data.signup_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* timedelta to days conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       143 days\n1        96 days\n2         1 days\n3       170 days\n4        47 days\n          ...   \n49995   131 days\n49996     1 days\n49997   111 days\n49998     1 days\n49999    92 days\nName: subscription_days, Length: 50000, dtype: timedelta64[ns]"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "churn_data['subscription_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data['subscription_days'] = churn_data.subscription_days.dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0        143\n1         96\n2          1\n3        170\n4         47\n        ... \n49995    131\n49996      1\n49997    111\n49998      1\n49999     92\nName: subscription_days, Length: 50000, dtype: int64"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "churn_data['subscription_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50000 entries, 0 to 49999\nData columns (total 14 columns):\n #   Column                  Non-Null Count  Dtype         \n---  ------                  --------------  -----         \n 0   avg_dist                50000 non-null  float64       \n 1   avg_rating_by_driver    49799 non-null  float64       \n 2   avg_rating_of_driver    41878 non-null  float64       \n 3   avg_surge               50000 non-null  float64       \n 4   city                    50000 non-null  object        \n 5   last_trip_date          50000 non-null  datetime64[ns]\n 6   phone                   49604 non-null  object        \n 7   signup_date             50000 non-null  datetime64[ns]\n 8   surge_pct               50000 non-null  float64       \n 9   trips_in_first_30_days  50000 non-null  int64         \n 10  luxury_car_user         50000 non-null  bool          \n 11  weekday_pct             50000 non-null  float64       \n 12  churn                   50000 non-null  object        \n 13  subscription_days       50000 non-null  int64         \ndtypes: bool(1), datetime64[ns](2), float64(6), int64(2), object(3)\nmemory usage: 4.4+ MB\n"
    }
   ],
   "source": [
    "churn_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_churn_data = churn_data.select_dtypes(include=['int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50000 entries, 0 to 49999\nEmpty DataFrame"
    }
   ],
   "source": [
    "int_churn_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_pipeline = make_pipeline(MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (int_pipeline,int_churn_data.columns),\n",
    "    (cat_pipeline,cat_churn_data.columns),\n",
    "    (float_pipeline,float_churn_data.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "churn        31690\nNot churn    18310\nName: churn, dtype: int64"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "churn_data.churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessor,RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX,trainY,testY = train_test_split(churn_data.drop(columns=['churn']), churn_data.churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('pipeline-1',\n                                                  Pipeline(steps=[('minmaxscaler',\n                                                                   MinMaxScaler())]),\n                                                  Index([], dtype='object')),\n                                                 ('pipeline-2',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('ordinalencoder',\n                                                                   OrdinalEncoder())]),\n                                                  Index(['city', 'phone'], dtype='object')),\n                                                 ('pipeline-3',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('minmaxscaler',\n                                                                   MinMaxScaler())]),\n                                                  Index(['avg_dist', 'avg_rating_by_driver', 'avg_rating_of_driver', 'avg_surge',\n       'surge_pct', 'luxury_car_user', 'weekday_pct'],\n      dtype='object'))])),\n                ('randomforestclassifier', RandomForestClassifier())])"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "pipeline.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.74752"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "pipeline.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['Not churn', 'churn', 'Not churn', ..., 'churn', 'churn',\n       'Not churn'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "30987    Not churn\n19911        churn\n2477         churn\n35341        churn\n3932     Not churn\n           ...    \n8727         churn\n26178    Not churn\n41433        churn\n3432         churn\n49487    Not churn\nName: churn, Length: 12500, dtype: object"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2894, 1616],\n       [1540, 6450]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipeline,param_grid={'randomforestclassifier__n_estimators':[300,400,500]},cv= 5,n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('columntransformer',\n                                        ColumnTransformer(transformers=[('pipeline-1',\n                                                                         Pipeline(steps=[('minmaxscaler',\n                                                                                          MinMaxScaler())]),\n                                                                         Index([], dtype='object')),\n                                                                        ('pipeline-2',\n                                                                         Pipeline(steps=[('simpleimputer',\n                                                                                          SimpleImputer(strategy='most_frequent')),\n                                                                                         ('ordinalencoder',\n                                                                                          OrdinalEncoder())]),\n                                                                         Index(['city', 'phone'], dtype='object'...\n                                                                         Pipeline(steps=[('simpleimputer',\n                                                                                          SimpleImputer(strategy='median')),\n                                                                                         ('minmaxscaler',\n                                                                                          MinMaxScaler())]),\n                                                                         Index(['avg_dist', 'avg_rating_by_driver', 'avg_rating_of_driver', 'avg_surge',\n       'surge_pct', 'luxury_car_user', 'weekday_pct'],\n      dtype='object'))])),\n                                       ('randomforestclassifier',\n                                        RandomForestClassifier())]),\n             n_jobs=4,\n             param_grid={'randomforestclassifier__n_estimators': [300, 400,\n                                                                  500]})"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "gs.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7436799999999999"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'randomforestclassifier__n_estimators': 300}"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessor,GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('pipeline-1',\n                                                  Pipeline(steps=[('minmaxscaler',\n                                                                   MinMaxScaler())]),\n                                                  Index([], dtype='object')),\n                                                 ('pipeline-2',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('ordinalencoder',\n                                                                   OrdinalEncoder())]),\n                                                  Index(['city', 'phone'], dtype='object')),\n                                                 ('pipeline-3',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('minmaxscaler',\n                                                                   MinMaxScaler())]),\n                                                  Index(['avg_dist', 'avg_rating_by_driver', 'avg_rating_of_driver', 'avg_surge',\n       'surge_pct', 'luxury_car_user', 'weekday_pct'],\n      dtype='object'))])),\n                ('gaussiannb', GaussianNB())])"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "pipeline.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.64512"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "pipeline.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RandomForest 0.7508\nGaussianNB 0.64512\nLogisticReg 0.6836\n"
    }
   ],
   "source": [
    "for name,estimator in zip(['RandomForest','GaussianNB','LogisticReg'],[RandomForestClassifier(n_estimators=100),GaussianNB(),LogisticRegression()]):\n",
    "    pipeline = make_pipeline(preprocessor,estimator)\n",
    "    pipeline.fit(trainX,trainY)\n",
    "    print(name,pipeline.score(testX,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Fine tuning \n",
    "* Feature Selection\n",
    "* Balancing Data \n",
    "* More Hyper-parameter tuning \n",
    "* Consider month column from date-time cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}